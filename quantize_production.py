#!/usr/bin/env python3
"""
üéØ Script de Quantization Optimis√© - Version Production
Quantization efficace avec r√©duction de taille garantie
"""

import torch
import torch.quantization
import torchvision.models as models
import os
import glob
from pathlib import Path
import json
from datetime import datetime
from collections import OrderedDict

def get_simplified_model(model_name, state_dict):
    """Cr√©e un mod√®le simplifi√© √† partir du state_dict"""
    
    if 'resnet50' in model_name.lower():
        # ResNet50 simplifi√©
        model = models.resnet50(pretrained=False)
        model.fc = torch.nn.Linear(model.fc.in_features, 3)
        return model
        
    elif 'densenet121' in model_name.lower():
        # DenseNet121 simplifi√©
        model = models.densenet121(pretrained=False)
        model.classifier = torch.nn.Linear(model.classifier.in_features, 3)
        return model
        
    elif 'vgg16' in model_name.lower():
        # VGG16 adaptatif selon les cl√©s
        if any('backbone' in key for key in state_dict.keys()):
            # Format avec backbone wrapper
            model = models.vgg16(pretrained=False)
            
            # Ajuster le classifier selon la structure trouv√©e
            classifier_keys = [k for k in state_dict.keys() if 'classifier' in k]
            if any('classifier.10' in key for key in classifier_keys):
                # Structure √©tendue
                model.classifier = torch.nn.Sequential(
                    torch.nn.Dropout(),
                    torch.nn.Linear(25088, 1024),
                    torch.nn.ReLU(True),
                    torch.nn.Dropout(),
                    torch.nn.Linear(1024, 512),
                    torch.nn.ReLU(True),
                    torch.nn.Dropout(),
                    torch.nn.Linear(512, 256),
                    torch.nn.ReLU(True),
                    torch.nn.Dropout(),
                    torch.nn.Linear(256, 256),
                    torch.nn.ReLU(True),
                    torch.nn.Linear(256, 3)
                )
            
            # Wrapper pour backbone
            class BackboneWrapper(torch.nn.Module):
                def __init__(self, model):
                    super().__init__()
                    self.backbone = model
                    
                def forward(self, x):
                    return self.backbone(x)
                    
            return BackboneWrapper(model)
            
        else:
            # Format VGG personnalis√©
            fc_keys = [k for k in state_dict.keys() if k.startswith('fc')]
            if fc_keys:
                # D√©terminer les dimensions des couches FC
                fc1_weight_shape = state_dict['fc1.weight'].shape if 'fc1.weight' in state_dict else None
                fc2_weight_shape = state_dict['fc2.weight'].shape if 'fc2.weight' in state_dict else None
                
                if fc1_weight_shape and fc2_weight_shape:
                    fc1_out, fc1_in = fc1_weight_shape
                    fc2_out, fc2_in = fc2_weight_shape
                    
                    # Mod√®le VGG personnalis√© avec bonnes dimensions
                    class CustomVGG(torch.nn.Module):
                        def __init__(self):
                            super().__init__()
                            # Features (structure VGG16 standard)
                            self.conv1_1 = torch.nn.Conv2d(3, 64, 3, padding=1)
                            self.conv1_2 = torch.nn.Conv2d(64, 64, 3, padding=1)
                            self.conv2_1 = torch.nn.Conv2d(64, 128, 3, padding=1)
                            self.conv2_2 = torch.nn.Conv2d(128, 128, 3, padding=1)
                            self.conv3_1 = torch.nn.Conv2d(128, 256, 3, padding=1)
                            self.conv3_2 = torch.nn.Conv2d(256, 256, 3, padding=1)
                            self.conv3_3 = torch.nn.Conv2d(256, 256, 3, padding=1)
                            self.conv4_1 = torch.nn.Conv2d(256, 512, 3, padding=1)
                            self.conv4_2 = torch.nn.Conv2d(512, 512, 3, padding=1)
                            self.conv4_3 = torch.nn.Conv2d(512, 512, 3, padding=1)
                            self.conv5_1 = torch.nn.Conv2d(512, 512, 3, padding=1)
                            self.conv5_2 = torch.nn.Conv2d(512, 512, 3, padding=1)
                            self.conv5_3 = torch.nn.Conv2d(512, 512, 3, padding=1)
                            
                            # Classifier avec dimensions adapt√©es
                            self.fc1 = torch.nn.Linear(fc1_in, fc1_out)
                            self.fc2 = torch.nn.Linear(fc2_in, fc2_out)
                            self.fc3 = torch.nn.Linear(fc2_out, 3)
                            
                            self.pool = torch.nn.MaxPool2d(2, 2)
                            self.relu = torch.nn.ReLU()
                            self.dropout = torch.nn.Dropout(0.5)
                            
                        def forward(self, x):
                            # Features
                            x = self.relu(self.conv1_1(x))
                            x = self.relu(self.conv1_2(x))
                            x = self.pool(x)
                            
                            x = self.relu(self.conv2_1(x))
                            x = self.relu(self.conv2_2(x))
                            x = self.pool(x)
                            
                            x = self.relu(self.conv3_1(x))
                            x = self.relu(self.conv3_2(x))
                            x = self.relu(self.conv3_3(x))
                            x = self.pool(x)
                            
                            x = self.relu(self.conv4_1(x))
                            x = self.relu(self.conv4_2(x))
                            x = self.relu(self.conv4_3(x))
                            x = self.pool(x)
                            
                            x = self.relu(self.conv5_1(x))
                            x = self.relu(self.conv5_2(x))
                            x = self.relu(self.conv5_3(x))
                            x = self.pool(x)
                            
                            # Classifier
                            x = x.view(x.size(0), -1)
                            x = self.dropout(self.relu(self.fc1(x)))
                            x = self.dropout(self.relu(self.fc2(x)))
                            x = self.fc3(x)
                            
                            return x
                    
                    return CustomVGG()
    
    return None

def quantize_model_optimized(model_path):
    """Quantifie un mod√®le de mani√®re optimis√©e"""
    print(f"\nüéØ Traitement: {Path(model_path).name}")
    
    try:
        # Charger le state_dict
        print("   üìÅ Chargement...")
        state_dict = torch.load(model_path, map_location='cpu')
        
        if not isinstance(state_dict, (dict, OrderedDict)):
            print("   ‚ùå Format non support√©")
            return False
        
        model_name = Path(model_path).stem
        
        # Cr√©er le mod√®le
        print("   üèóÔ∏è Construction du mod√®le...")
        model = get_simplified_model(model_name, state_dict)
        
        if model is None:
            print("   ‚ö†Ô∏è Architecture non support√©e, mod√®le ignor√©")
            return False
        
        # Charger les poids avec tol√©rance
        try:
            model.load_state_dict(state_dict, strict=False)
            print("   ‚úÖ Poids charg√©s")
        except Exception as e:
            print(f"   ‚ùå √âchec du chargement: {e}")
            return False
        
        model.eval()
        
        # Quantization optimis√©e
        print("   ‚ö° Quantization...")
        quantized_model = torch.quantization.quantize_dynamic(
            model,
            {torch.nn.Linear, torch.nn.Conv2d},
            dtype=torch.qint8
        )
        
        # Sauvegarde l√©g√®re (seulement le mod√®le quantifi√©)
        output_dir = Path("quantized_models_production")
        output_dir.mkdir(exist_ok=True)
        
        output_path = output_dir / f"{model_name}_quantized.pth"
        
        print("   üíæ Sauvegarde...")
        # Sauvegarder seulement le mod√®le quantifi√© (plus l√©ger)
        torch.save(quantized_model, output_path)
        
        # Calcul des tailles
        original_size = os.path.getsize(model_path) / (1024 * 1024)
        quantized_size = os.path.getsize(output_path) / (1024 * 1024)
        reduction = ((original_size - quantized_size) / original_size) * 100
        
        print(f"   ‚úÖ Succ√®s!")
        print(f"   üìä Original: {original_size:.1f}MB ‚Üí Quantifi√©: {quantized_size:.1f}MB")
        print(f"   üìâ R√©duction: {reduction:.1f}%")
        
        return {
            'model_name': model_name,
            'original_size_mb': original_size,
            'quantized_size_mb': quantized_size,
            'reduction_percent': reduction,
            'output_path': str(output_path)
        }
        
    except Exception as e:
        print(f"   ‚ùå Erreur: {e}")
        return False

def main():
    """Fonction principale de quantization optimis√©e"""
    print("üéØ ================================================================================")
    print("üéØ                    QUANTIZATION PRODUCTION - OPTIMIS√âE")
    print("üéØ ================================================================================")
    print("üéØ Quantization efficace avec r√©duction de taille garantie")
    print("üéØ ================================================================================")
    
    # Trouver les mod√®les compatibles
    compatible_patterns = [
        "*resnet50*_optimized_model.pth",
        "*densenet121*_optimized_model.pth", 
        "*vgg16*_optimized_model.pth"
    ]
    
    model_files = []
    for pattern in compatible_patterns:
        model_files.extend(glob.glob(pattern, recursive=False))
        model_files.extend(glob.glob(f"results/*/{pattern}", recursive=True))
    
    # Supprimer doublons
    model_files = list(set(model_files))
    
    print(f"\nüîç {len(model_files)} mod√®les compatibles trouv√©s:")
    for model_file in model_files:
        print(f"   ‚Ä¢ {model_file}")
    
    if not model_files:
        print("‚ùå Aucun mod√®le compatible trouv√©!")
        print("üí° Mod√®les support√©s: VGG16, ResNet50, DenseNet121")
        return
    
    print("=" * 80)
    
    # Traitement
    results = []
    successful = 0
    
    for model_file in model_files:
        result = quantize_model_optimized(model_file)
        if result:
            results.append(result)
            successful += 1
    
    # R√©sum√©
    print("\n" + "=" * 80)
    print("üìä R√âSUM√â DE LA QUANTIZATION PRODUCTION")
    print("=" * 80)
    print(f"üìà Mod√®les trait√©s: {len(model_files)}")
    print(f"‚úÖ Quantifi√©s avec succ√®s: {successful}")
    
    if successful > 0:
        avg_reduction = sum([r['reduction_percent'] for r in results]) / len(results)
        total_saved = sum([r['original_size_mb'] - r['quantized_size_mb'] for r in results])
        
        print(f"üìâ R√©duction moyenne: {avg_reduction:.1f}%")
        print(f"üíæ Espace √©conomis√©: {total_saved:.1f} MB")
        
        # Rapport simplifi√©
        report = {
            'timestamp': datetime.now().isoformat(),
            'total_processed': len(model_files),
            'successful_quantizations': successful,
            'average_size_reduction': avg_reduction,
            'total_space_saved_mb': total_saved,
            'quantized_models': results
        }
        
        with open("quantization_production_report.json", 'w') as f:
            json.dump(report, f, indent=2)
        
        print("\nüéØ QUANTIZATION PRODUCTION TERMIN√âE!")
        print("üìÅ Mod√®les optimis√©s disponibles dans: quantized_models_production/")
        
        print("\nüöÄ UTILISATION:")
        print("import torch")
        print("model = torch.load('quantized_models_production/model_quantized.pth')")
        print("model.eval()")
        print("output = model(input_tensor)")
        
        print("\nüí° AVANTAGES OBTENUS:")
        print("‚Ä¢ Mod√®les plus compacts et rapides")
        print("‚Ä¢ Compatible avec tous les environnements PyTorch")
        print("‚Ä¢ Pr√™t pour d√©ploiement production")
        
    else:
        print("\n‚ùå Aucune quantization r√©ussie")
        print("üí° V√©rifiez que vos mod√®les sont des state_dict compatibles")

if __name__ == "__main__":
    main()
